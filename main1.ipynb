{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T07:59:12.430632Z",
     "start_time": "2024-05-05T07:59:05.585485Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T08:47:47.024739Z",
     "start_time": "2024-05-05T08:47:47.011409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-proj-PWTQRqXsFli77OLdL6j3T3BlbkFJCkblWFZp1KOOC53vhfhU'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T07:59:20.639862Z",
     "start_time": "2024-05-05T07:59:20.636709Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T11:18:18.321018Z",
     "start_time": "2024-05-05T11:18:13.932716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A computer is a programmable electronic device that can store, retrieve, and process data. It can perform various tasks, such as calculations, data processing, and communication. Computers consist of hardware components, such as a central processing unit (CPU), memory, storage devices, and input/output devices, as well as software programs that enable users to interact with the computer and perform specific tasks. Computers come in various forms, including desktop computers, laptops, tablets, and smartphones.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "output = llm.invoke(\"what is Computer?\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain .chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "template = '''You are AI Researcher,\n",
    "write a few sentence about following topic {topic} in {language}'''\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = LLMChain(\n",
    "\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "\n",
    ")\n",
    "\n",
    "output = chain.invoke({\"topic\": \"Language translation model\", \"language\": \"English\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mwhat is capital of Bangladesh? List the top 3 places to visit in that city. Use bullet points.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The capital of Bangladesh is Dhaka.\n",
      "\n",
      "Top 3 places to visit in Dhaka:\n",
      "- Lalbagh Fort\n",
      "- Ahsan Manzil (Pink Palace)\n",
      "- National Parliament House\n"
     ]
    }
   ],
   "source": [
    "template = 'what is capital of {country}? List the top 3 places to visit in that city. Use bullet points.'\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "chain = LLMChain(\n",
    "\n",
    "    llm=llm,\n",
    "    prompt=prompt_template,\n",
    "    verbose=True\n",
    ")\n",
    "country = input(\"Enter the country name: \")\n",
    "\n",
    "output = chain.invoke(country)\n",
    "\n",
    "print(output['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure, here is a Python function that implements the bubble sort algorithm:\n",
      "\n",
      "```python\n",
      "def bubble_sort(arr):\n",
      "    n = len(arr)\n",
      "    for i in range(n):\n",
      "        for j in range(0, n-i-1):\n",
      "            if arr[j] > arr[j+1]:\n",
      "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "    return arr\n",
      "\n",
      "# Example usage\n",
      "arr = [64, 34, 25, 12, 22, 11, 90]\n",
      "sorted_arr = bubble_sort(arr)\n",
      "print(\"Sorted array:\", sorted_arr)\n",
      "```\n",
      "\n",
      "This function takes a list as input and sorts it using the bubble sort algorithm. It iterates through the list multiple times, comparing adjacent elements and swapping them if they are in the wrong order. The process is repeated until the list is fully sorted.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe `bubble_sort` function takes a list `arr` as input and sorts it in ascending order. It uses a nested loop structure to iterate over the list. \n",
      "\n",
      "The outer loop runs `n` times, where `n` is the length of the input list. This loop controls the number of iterations needed to sort the list. \n",
      "\n",
      "The inner loop runs from index 0 to `n-i-1`, where `i` is the current iteration of the outer loop. This loop compares adjacent elements in the list and swaps them if they are in the wrong order. \n",
      "\n",
      "If the element at index `j` is greater than the element at index `j+1`, they are swapped using tuple unpacking: `arr[j], arr[j+1] = arr[j+1], arr[j]`. This swaps the elements in place without needing a temporary variable. \n",
      "\n",
      "After completing all iterations, the sorted list is returned. \n",
      "\n",
      "The example usage demonstrates how to call the function with an example list `[64, 34, 25, 12, 22, 11, 90]` and prints the sorted list. In this case, the sorted array would be `[11, 12, 22, 25, 34, 64, 90]`.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 =  ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "prompt1 = 'you are experienced python developer, write a function that implements concept of {concept} '\n",
    "prompt_template1 = PromptTemplate.from_template(prompt1)\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "llm2 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.9)\n",
    "prompt2 = 'Given Pyhton function {function}, describe it as detailed as possible'\n",
    "prompt_template2 = PromptTemplate.from_template(prompt2)\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.invoke('bubble sort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mSure! Here is a Python function that implements the bubble sort algorithm:\n",
      "\n",
      "```python\n",
      "def bubble_sort(arr):\n",
      "    n = len(arr)\n",
      "    for i in range(n):\n",
      "        for j in range(0, n-i-1):\n",
      "            if arr[j] > arr[j+1]:\n",
      "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
      "    return arr\n",
      "```\n",
      "\n",
      "You can use this function by passing a list of numbers as an argument, and it will return the sorted list using the bubble sort algorithm.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThis Python function, `bubble_sort`, takes a list `arr` as input and implements the bubble sort algorithm to sort the elements in ascending order.\n",
      "\n",
      "Here's how the function works:\n",
      "1. It first determines the length of the input list `arr` using `n = len(arr)`.\n",
      "2. It then iterates over the list `arr` `n` times using a loop with `i` ranging from `0` to `n-1`.\n",
      "3. Within each iteration of the outer loop, another loop iterates over the list `arr` from index `0` to `n-i-1`. This inner loop is used to compare adjacent elements in the list.\n",
      "4. If the element at index `j` is greater than the element at index `j+1`, the function swaps these two elements using a tuple assignment: `arr[j], arr[j+1] = arr[j+1], arr[j]`. This way, the larger element \"bubbles up\" towards the end of the list.\n",
      "5. After completing all iterations, the function returns the sorted list `arr`.\n",
      "\n",
      "You can use this function by passing a list of numbers, for example:\n",
      "\n",
      "```python\n",
      "unsorted_list = [64, 34, 25, 12, 22, 11, 90]\n",
      "sorted_list = bubble_sort(unsorted_list)\n",
      "print(sorted_list)\n",
      "```\n",
      "\n",
      "This will output:\n",
      "```\n",
      "[11, 12, 22, 25, 34, 64, 90]\n",
      "```\n",
      "\n",
      "This shows how the bubble sort algorithm works by repeatedly swapping adjacent elements if they are in the wrong order until the entire list is sorted in ascending order.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "# Initialize the first LLM chain\n",
    "llm1 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "prompt1 = 'you are experienced python developer, write a function that implements bubble concept of {concept}'\n",
    "prompt_template1 = PromptTemplate.from_template(prompt1)\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt_template1)\n",
    "\n",
    "# Initialize the second LLM chain\n",
    "llm2 = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.9)  # Adjusted temperature for typical usage\n",
    "prompt2 = 'Given Python function {function}, describe it as detailed as possible'\n",
    "prompt_template2 = PromptTemplate.from_template(prompt2)\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt_template2)\n",
    "\n",
    "# Combine into a sequential chain\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.invoke('bubble sort')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `bubble_sort` function takes a list `arr` as input and sorts it in ascending order. It uses a nested loop structure to iterate over the list. \n",
      "\n",
      "The outer loop runs `n` times, where `n` is the length of the input list. This loop controls the number of iterations needed to sort the list. \n",
      "\n",
      "The inner loop runs from index 0 to `n-i-1`, where `i` is the current iteration of the outer loop. This loop compares adjacent elements in the list and swaps them if they are in the wrong order. \n",
      "\n",
      "If the element at index `j` is greater than the element at index `j+1`, they are swapped using tuple unpacking: `arr[j], arr[j+1] = arr[j+1], arr[j]`. This swaps the elements in place without needing a temporary variable. \n",
      "\n",
      "After completing all iterations, the sorted list is returned. \n",
      "\n",
      "The example usage demonstrates how to call the function with an example list `[64, 34, 25, 12, 22, 11, 90]` and prints the sorted list. In this case, the sorted array would be `[11, 12, 22, 25, 34, 64, 90]`.\n"
     ]
    }
   ],
   "source": [
    "print(output['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[13, 26, 39, 52, 65, 78, 91]\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "python_repl = PythonREPL()\n",
    "python_repl.run('print([n for n in range(1, 100) if n % 13 == 0])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo solve this, I need to calculate the factorial of 12 first, then find its square root, and finally format the result to display it with 4 decimal points. I can use the `math` module in Python to accomplish this, as it provides both the `factorial` and `sqrt` functions.\n",
      "Action: Python_REPL\n",
      "Action Input: import math\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that the math module is imported, I can calculate the factorial of 12.\n",
      "Action: Python_REPL\n",
      "Action Input: factorial_12 = math.factorial(12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWith the factorial of 12 calculated, I can now find its square root.\n",
      "Action: Python_REPL\n",
      "Action Input: sqrt_factorial_12 = math.sqrt(factorial_12)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the square root of the factorial of 12, I need to format it to display with 4 decimal points.\n",
      "Action: Python_REPL\n",
      "Action Input: print(f\"{sqrt_factorial_12:.4f}\")\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m21886.1052\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: 21886.1052\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Calculate the square root of the factorial of 12 and display it with 4 decimal points',\n",
       " 'output': '21886.1052'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the ChatOpenAI model with gpt-4-turbo and a temperature of 0\n",
    "llm = ChatOpenAI(model='gpt-3-turbo-preview', temperature=0)\n",
    "\n",
    "# Create a Python agent using the ChatOpenAI model and a PythonREPLTool\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "prompt = 'Calculate the square root of the factorial of 12 and display it with 4 decimal points'\n",
    "agent_executor.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the square root of 144 using Python.\n",
      "Action: Python_REPL\n",
      "Action Input: print(144**0.5)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m12.0\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: The square root of 144 is 12.0.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the square root of 144?',\n",
       " 'output': 'The square root of 144 is 12.0.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = agent_executor.invoke(\"what is the square root of 144?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The square root of 144 is 12.0.\n"
     ]
    }
   ],
   "source": [
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the square root of 144?\n"
     ]
    }
   ],
   "source": [
    "print(response['input'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "RatelimitException",
     "evalue": "https://links.duckduckgo.com/d.js?q=who+was+the+Amir+Temur%3F&kl=wt-wt&l=wt-wt&p=&s=0&df=y&vqd=4-105160336442418445296773116866915283833&ex=-1 202 Ratelimit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRatelimitException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m DuckDuckGoSearchRun\n\u001b[1;32m      3\u001b[0m search \u001b[39m=\u001b[39m DuckDuckGoSearchRun()\n\u001b[0;32m----> 5\u001b[0m output \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49minvoke(\u001b[39m\"\u001b[39;49m\u001b[39mwho was the Amir Temur?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_core/tools.py:260\u001b[0m, in \u001b[0;36mBaseTool.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[1;32m    254\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    255\u001b[0m     \u001b[39minput\u001b[39m: Union[\u001b[39mstr\u001b[39m, Dict],\n\u001b[1;32m    256\u001b[0m     config: Optional[RunnableConfig] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    257\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    258\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    259\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 260\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    261\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[1;32m    262\u001b[0m         callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    263\u001b[0m         tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    264\u001b[0m         metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    265\u001b[0m         run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    266\u001b[0m         run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    267\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    268\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    269\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_core/tools.py:452\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 452\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_end(observation, color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_core/tools.py:409\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     parsed_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_input(tool_input)\n\u001b[1;32m    407\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    408\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 409\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    410\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run, \u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    413\u001b[0m         \u001b[39melse\u001b[39;00m context\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run, \u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[1;32m    414\u001b[0m     )\n\u001b[1;32m    415\u001b[0m \u001b[39mexcept\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_community/tools/ddg_search/tool.py:39\u001b[0m, in \u001b[0;36mDuckDuckGoSearchRun._run\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run\u001b[39m(\n\u001b[1;32m     34\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     35\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     36\u001b[0m     run_manager: Optional[CallbackManagerForToolRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     38\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_wrapper\u001b[39m.\u001b[39;49mrun(query)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:81\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper.run\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run query through DuckDuckGo and return concatenated results.\"\"\"\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 81\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ddgs_text(query)\n\u001b[1;32m     82\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnews\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     83\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ddgs_news(query)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:48\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper._ddgs_text\u001b[0;34m(self, query, max_results)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mduckduckgo_search\u001b[39;00m \u001b[39mimport\u001b[39;00m DDGS\n\u001b[1;32m     47\u001b[0m \u001b[39mwith\u001b[39;00m DDGS() \u001b[39mas\u001b[39;00m ddgs:\n\u001b[0;32m---> 48\u001b[0m     ddgs_gen \u001b[39m=\u001b[39m ddgs\u001b[39m.\u001b[39;49mtext(\n\u001b[1;32m     49\u001b[0m         query,\n\u001b[1;32m     50\u001b[0m         region\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregion,\n\u001b[1;32m     51\u001b[0m         safesearch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msafesearch,\n\u001b[1;32m     52\u001b[0m         timelimit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtime,\n\u001b[1;32m     53\u001b[0m         max_results\u001b[39m=\u001b[39;49mmax_results \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_results,\n\u001b[1;32m     54\u001b[0m         backend\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackend,\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m ddgs_gen:\n\u001b[1;32m     57\u001b[0m         \u001b[39mreturn\u001b[39;00m [r \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m ddgs_gen]\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search.py:57\u001b[0m, in \u001b[0;36mDDGS.text\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_async_in_thread(\u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search.py:53\u001b[0m, in \u001b[0;36mDDGS._run_async_in_thread\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs an async coroutine in a separate thread.\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m future: Future[Any] \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loop)\n\u001b[0;32m---> 53\u001b[0m result \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:167\u001b[0m, in \u001b[0;36mAsyncDDGS.text\u001b[0;34m(self, keywords, region, safesearch, timelimit, backend, max_results)\u001b[0m\n\u001b[1;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mlxml is not installed. Using backend=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mapi\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapi\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 167\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_api(keywords, region, safesearch, timelimit, max_results)\n\u001b[1;32m    168\u001b[0m \u001b[39melif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhtml\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_html(keywords, region, safesearch, timelimit, max_results)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:258\u001b[0m, in \u001b[0;36mAsyncDDGS._text_api\u001b[0;34m(self, keywords, region, safesearch, timelimit, max_results)\u001b[0m\n\u001b[1;32m    256\u001b[0m         task\u001b[39m.\u001b[39mcancel()\n\u001b[1;32m    257\u001b[0m     \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39mtasks, return_exceptions\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    260\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(islice(\u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, results), max_results))\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:253\u001b[0m, in \u001b[0;36mAsyncDDGS._text_api\u001b[0;34m(self, keywords, region, safesearch, timelimit, max_results)\u001b[0m\n\u001b[1;32m    249\u001b[0m     tasks\u001b[39m.\u001b[39mextend(\n\u001b[1;32m    250\u001b[0m         asyncio\u001b[39m.\u001b[39mcreate_task(_text_api_page(s, i)) \u001b[39mfor\u001b[39;00m i, s \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m23\u001b[39m, max_results, \u001b[39m50\u001b[39m), start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39mtasks)\n\u001b[1;32m    254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    255\u001b[0m     \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m tasks:\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:229\u001b[0m, in \u001b[0;36mAsyncDDGS._text_api.<locals>._text_api_page\u001b[0;34m(s, page)\u001b[0m\n\u001b[1;32m    227\u001b[0m priority \u001b[39m=\u001b[39m page \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m    228\u001b[0m payload[\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 229\u001b[0m resp_content \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aget_url(\u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhttps://links.duckduckgo.com/d.js\u001b[39m\u001b[39m\"\u001b[39m, params\u001b[39m=\u001b[39mpayload)\n\u001b[1;32m    230\u001b[0m page_data \u001b[39m=\u001b[39m _text_extract_json(resp_content, keywords)\n\u001b[1;32m    232\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m page_data:\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:124\u001b[0m, in \u001b[0;36mAsyncDDGS._aget_url\u001b[0;34m(self, method, url, data, params)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_event\u001b[39m.\u001b[39mset()\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39min\u001b[39;00m (\u001b[39m202\u001b[39m, \u001b[39m301\u001b[39m, \u001b[39m403\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mraise\u001b[39;00m RatelimitException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresp\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mresp\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Ratelimit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[39mraise\u001b[39;00m DuckDuckGoSearchException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresp\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m return None. \u001b[39m\u001b[39m{\u001b[39;00mparams\u001b[39m=}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRatelimitException\u001b[0m: https://links.duckduckgo.com/d.js?q=who+was+the+Amir+Temur%3F&kl=wt-wt&l=wt-wt&p=&s=0&df=y&vqd=4-105160336442418445296773116866915283833&ex=-1 202 Ratelimit"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "output = search.invoke(\"who was the Amir Temur?\")\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duckduckgo_search'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around DuckDuckGo Search. Useful for when you need to answer questions about current events. Input should be a search query.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "RatelimitException",
     "evalue": "https://links.duckduckgo.com/d.js?q=Freddie+Mercury+and+Queen.&kl=wt-wt&l=wt-wt&p=&s=0&df=y&vqd=4-61488056995309775070939320376474485721&ex=-1 202 Ratelimit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRatelimitException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m DuckDuckGoSearchResults\n\u001b[1;32m      2\u001b[0m search \u001b[39m=\u001b[39m DuckDuckGoSearchResults()\n\u001b[0;32m----> 3\u001b[0m output \u001b[39m=\u001b[39m search\u001b[39m.\u001b[39;49mrun(\u001b[39m'\u001b[39;49m\u001b[39mFreddie Mercury and Queen.\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_core/tools.py:452\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_error(e)\n\u001b[0;32m--> 452\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    453\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     run_manager\u001b[39m.\u001b[39mon_tool_end(observation, color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_core/tools.py:409\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m     parsed_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_input(tool_input)\n\u001b[1;32m    407\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_args_and_kwargs(parsed_input)\n\u001b[1;32m    408\u001b[0m     observation \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 409\u001b[0m         context\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    410\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run, \u001b[39m*\u001b[39;49mtool_args, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs\n\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    413\u001b[0m         \u001b[39melse\u001b[39;00m context\u001b[39m.\u001b[39mrun(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run, \u001b[39m*\u001b[39mtool_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtool_kwargs)\n\u001b[1;32m    414\u001b[0m     )\n\u001b[1;32m    415\u001b[0m \u001b[39mexcept\u001b[39;00m ValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    416\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_validation_error:\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_community/tools/ddg_search/tool.py:64\u001b[0m, in \u001b[0;36mDuckDuckGoSearchResults._run\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run\u001b[39m(\n\u001b[1;32m     59\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     60\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     61\u001b[0m     run_manager: Optional[CallbackManagerForToolRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     62\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Use the tool.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_wrapper\u001b[39m.\u001b[39;49mresults(query, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_results, source\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackend)\n\u001b[1;32m     65\u001b[0m     res_strs \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mitems()]) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m res]\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mrs\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m rs \u001b[39min\u001b[39;00m res_strs])\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:111\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper.results\u001b[0;34m(self, query, max_results, source)\u001b[0m\n\u001b[1;32m    107\u001b[0m source \u001b[39m=\u001b[39m source \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource\n\u001b[1;32m    108\u001b[0m \u001b[39mif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    109\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m    110\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39msnippet\u001b[39m\u001b[39m\"\u001b[39m: r[\u001b[39m\"\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: r[\u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m\"\u001b[39m: r[\u001b[39m\"\u001b[39m\u001b[39mhref\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[0;32m--> 111\u001b[0m         \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ddgs_text(query, max_results\u001b[39m=\u001b[39;49mmax_results)\n\u001b[1;32m    112\u001b[0m     ]\n\u001b[1;32m    113\u001b[0m \u001b[39melif\u001b[39;00m source \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnews\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    114\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m    115\u001b[0m         {\n\u001b[1;32m    116\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msnippet\u001b[39m\u001b[39m\"\u001b[39m: r[\u001b[39m\"\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ddgs_news(query, max_results\u001b[39m=\u001b[39mmax_results)\n\u001b[1;32m    123\u001b[0m     ]\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/langchain_community/utilities/duckduckgo_search.py:48\u001b[0m, in \u001b[0;36mDuckDuckGoSearchAPIWrapper._ddgs_text\u001b[0;34m(self, query, max_results)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mduckduckgo_search\u001b[39;00m \u001b[39mimport\u001b[39;00m DDGS\n\u001b[1;32m     47\u001b[0m \u001b[39mwith\u001b[39;00m DDGS() \u001b[39mas\u001b[39;00m ddgs:\n\u001b[0;32m---> 48\u001b[0m     ddgs_gen \u001b[39m=\u001b[39m ddgs\u001b[39m.\u001b[39;49mtext(\n\u001b[1;32m     49\u001b[0m         query,\n\u001b[1;32m     50\u001b[0m         region\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mregion,\n\u001b[1;32m     51\u001b[0m         safesearch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msafesearch,\n\u001b[1;32m     52\u001b[0m         timelimit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtime,\n\u001b[1;32m     53\u001b[0m         max_results\u001b[39m=\u001b[39;49mmax_results \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_results,\n\u001b[1;32m     54\u001b[0m         backend\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackend,\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     \u001b[39mif\u001b[39;00m ddgs_gen:\n\u001b[1;32m     57\u001b[0m         \u001b[39mreturn\u001b[39;00m [r \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m ddgs_gen]\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search.py:57\u001b[0m, in \u001b[0;36mDDGS.text\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtext\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_async_in_thread(\u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtext(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search.py:53\u001b[0m, in \u001b[0;36mDDGS._run_async_in_thread\u001b[0;34m(self, coro)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Runs an async coroutine in a separate thread.\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m future: Future[Any] \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mrun_coroutine_threadsafe(coro, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loop)\n\u001b[0;32m---> 53\u001b[0m result \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    457\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:167\u001b[0m, in \u001b[0;36mAsyncDDGS.text\u001b[0;34m(self, keywords, region, safesearch, timelimit, backend, max_results)\u001b[0m\n\u001b[1;32m    164\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mlxml is not installed. Using backend=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mapi\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    166\u001b[0m \u001b[39mif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mapi\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 167\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_api(keywords, region, safesearch, timelimit, max_results)\n\u001b[1;32m    168\u001b[0m \u001b[39melif\u001b[39;00m backend \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhtml\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    169\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_html(keywords, region, safesearch, timelimit, max_results)\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:258\u001b[0m, in \u001b[0;36mAsyncDDGS._text_api\u001b[0;34m(self, keywords, region, safesearch, timelimit, max_results)\u001b[0m\n\u001b[1;32m    256\u001b[0m         task\u001b[39m.\u001b[39mcancel()\n\u001b[1;32m    257\u001b[0m     \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39mtasks, return_exceptions\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    260\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(islice(\u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, results), max_results))\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:253\u001b[0m, in \u001b[0;36mAsyncDDGS._text_api\u001b[0;34m(self, keywords, region, safesearch, timelimit, max_results)\u001b[0m\n\u001b[1;32m    249\u001b[0m     tasks\u001b[39m.\u001b[39mextend(\n\u001b[1;32m    250\u001b[0m         asyncio\u001b[39m.\u001b[39mcreate_task(_text_api_page(s, i)) \u001b[39mfor\u001b[39;00m i, s \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39m23\u001b[39m, max_results, \u001b[39m50\u001b[39m), start\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39mtasks)\n\u001b[1;32m    254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    255\u001b[0m     \u001b[39mfor\u001b[39;00m task \u001b[39min\u001b[39;00m tasks:\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:229\u001b[0m, in \u001b[0;36mAsyncDDGS._text_api.<locals>._text_api_page\u001b[0;34m(s, page)\u001b[0m\n\u001b[1;32m    227\u001b[0m priority \u001b[39m=\u001b[39m page \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m    228\u001b[0m payload[\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 229\u001b[0m resp_content \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aget_url(\u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhttps://links.duckduckgo.com/d.js\u001b[39m\u001b[39m\"\u001b[39m, params\u001b[39m=\u001b[39mpayload)\n\u001b[1;32m    230\u001b[0m page_data \u001b[39m=\u001b[39m _text_extract_json(resp_content, keywords)\n\u001b[1;32m    232\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m page_data:\n",
      "File \u001b[0;32m~/Desktop/generativeAI/.venv/lib/python3.12/site-packages/duckduckgo_search/duckduckgo_search_async.py:124\u001b[0m, in \u001b[0;36mAsyncDDGS._aget_url\u001b[0;34m(self, method, url, data, params)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception_event\u001b[39m.\u001b[39mset()\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39min\u001b[39;00m (\u001b[39m202\u001b[39m, \u001b[39m301\u001b[39m, \u001b[39m403\u001b[39m):\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mraise\u001b[39;00m RatelimitException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresp\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mresp\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Ratelimit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[39mraise\u001b[39;00m DuckDuckGoSearchException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresp\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m return None. \u001b[39m\u001b[39m{\u001b[39;00mparams\u001b[39m=}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mdata\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mRatelimitException\u001b[0m: https://links.duckduckgo.com/d.js?q=Freddie+Mercury+and+Queen.&kl=wt-wt&l=wt-wt&p=&s=0&df=y&vqd=4-61488056995309775070939320376474485721&ex=-1 202 Ratelimit"
     ]
    }
   ],
   "source": [
    "from langchain.tools import DuckDuckGoSearchResults\n",
    "search = DuckDuckGoSearchResults()\n",
    "output = search.run('Freddie Mercury and Queen.')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a simple 3D CNN Encoder\n",
    "class Encoder3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder3D, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "# Define a simple 2D CNN Encoder\n",
    "class Encoder2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "# Combined model that merges features from 3D and 2D encoders\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, encoder3D, encoder2D, num_classes):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.encoder3D = encoder3D\n",
    "        self.encoder2D = encoder2D\n",
    "        self.fc1 = nn.Linear(32 * 13 * 15 * 11 + 32 * 7 * 143, 512)  # Adjust this based on your actual output dimensions\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x3d, x2d):\n",
    "        features3d = self.encoder3D(x3d)\n",
    "        features2d = self.encoder2D(x2d)\n",
    "        # Flatten the outputs\n",
    "        features3d = torch.flatten(features3d, 1)\n",
    "        features2d = torch.flatten(features2d, 1)\n",
    "        # Concatenate the features from both encoders\n",
    "        combined_features = torch.cat((features3d, features2d), dim=1)\n",
    "        # Forward pass through the fully connected layers\n",
    "        x = self.relu(self.fc1(combined_features))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the encoders and the combined model\n",
    "encoder3D = Encoder3D()\n",
    "encoder2D = Encoder2D()\n",
    "combined_model = CombinedModel(encoder3D, encoder2D, num_classes=2)  # Binary classification\n",
    "\n",
    "# # Create example tensors for 3D and 2D data\n",
    "# x3d = torch.rand(200, 1, 53, 63, 46)  # Random synthetic 3D data\n",
    "# x2d = torch.rand(200, 1, 31, 575)     # Random synthetic 2D data\n",
    "\n",
    "# # Forward pass through the model\n",
    "# output = combined_model(x3d, x2d)\n",
    "# print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
